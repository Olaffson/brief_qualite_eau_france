{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1528b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, types as T, Window\n",
    "import os\n",
    "\n",
    "# ---------- Contexte & chemins ----------\n",
    "spark.sql(\"USE CATALOG hive_metastore\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")\n",
    "spark.sql(\"USE SCHEMA gold\")\n",
    "\n",
    "storage_account_name = os.environ[\"STORAGE_ACCOUNT_NAME\"]\n",
    "storage_account_key  = os.environ[\"STORAGE_ACCOUNT_KEY\"]\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net\", storage_account_key)\n",
    "\n",
    "gold_base     = f\"abfss://gold@{storage_account_name}.dfs.core.windows.net/\"\n",
    "gold_dim_comm = gold_base + \"dim_commune/\"\n",
    "gold_dim_res  = gold_base + \"dim_reseau/\"\n",
    "gold_dim_par  = gold_base + \"dim_parametre/\"\n",
    "gold_dim_time = gold_base + \"dim_temps/\"\n",
    "gold_f_prelev = gold_base + \"fact_prelevement/\"\n",
    "gold_f_res    = gold_base + \"fact_resultat/\"\n",
    "\n",
    "# ---------- Sources Silver ----------\n",
    "plv = spark.table(\"hive_metastore.silver.plv_silver\")\n",
    "res = spark.table(\"hive_metastore.silver.result_silver\")\n",
    "\n",
    "# ========= DIMENSIONS =========\n",
    "\n",
    "# -- DIM_TEMPS (à partir des dates de prélèvement) --\n",
    "# On part de plv.date_prelevement (format date recommandé dans Silver)\n",
    "dim_temps = (plv\n",
    "    .select(F.col(\"date_prelevement\").alias(\"date\"))\n",
    "    .where(F.col(\"date\").isNotNull())\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"date_key\", F.date_format(\"date\", \"yyyyMMdd\").cast(\"int\"))\n",
    "    .withColumn(\"year\", F.year(\"date\"))\n",
    "    .withColumn(\"quarter\", F.quarter(\"date\"))\n",
    "    .withColumn(\"month\", F.month(\"date\"))\n",
    "    .withColumn(\"week\", F.weekofyear(\"date\"))\n",
    "    .withColumn(\"day\", F.dayofmonth(\"date\"))\n",
    ")\n",
    "\n",
    "(dim_temps\n",
    " .write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\")\n",
    " .option(\"path\", gold_dim_time).saveAsTable(\"hive_metastore.gold.dim_temps\"))\n",
    "\n",
    "# -- DIM_COMMUNE --\n",
    "dim_commune = (plv\n",
    "    .select(\n",
    "        F.col(\"code_insee_commune\").alias(\"code_insee_commune\"),\n",
    "        F.col(\"nom_commune\").alias(\"nom_commune\"),\n",
    "        F.col(\"code_dept\").alias(\"code_dept\"),\n",
    "        F.col(\"annee\").alias(\"annee\")  # utile pour l'historique si besoin\n",
    "    )\n",
    "    .where(F.col(\"code_insee_commune\").isNotNull())\n",
    "    .dropDuplicates([\"code_insee_commune\", \"nom_commune\", \"code_dept\"])\n",
    ")\n",
    "\n",
    "# surrogate key stable (hash)\n",
    "dim_commune = dim_commune.withColumn(\n",
    "    \"commune_sk\",\n",
    "    F.sha2(F.concat_ws(\"||\", F.col(\"code_insee_commune\"), F.col(\"nom_commune\"), F.col(\"code_dept\")), 256)\n",
    ")\n",
    "\n",
    "(dim_commune\n",
    " .select(\"commune_sk\",\"code_insee_commune\",\"nom_commune\",\"code_dept\",\"annee\")\n",
    " .write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\")\n",
    " .option(\"path\", gold_dim_comm).saveAsTable(\"hive_metastore.gold.dim_commune\"))\n",
    "\n",
    "# -- DIM_RESEAU --\n",
    "dim_reseau = (plv\n",
    "    .select(\n",
    "        F.col(\"code_reseau\").alias(\"code_reseau\"),\n",
    "        F.col(\"nom_reseau_amont\").alias(\"nom_reseau_amont\"),\n",
    "        F.col(\"code_reseau_amont\").alias(\"code_reseau_amont\")\n",
    "    )\n",
    "    .where(F.col(\"code_reseau\").isNotNull())\n",
    "    .dropDuplicates([\"code_reseau\",\"nom_reseau_amont\",\"code_reseau_amont\"])\n",
    ")\n",
    "\n",
    "dim_reseau = dim_reseau.withColumn(\n",
    "    \"reseau_sk\",\n",
    "    F.sha2(F.concat_ws(\"||\", F.col(\"code_reseau\"), F.col(\"nom_reseau_amont\"), F.col(\"code_reseau_amont\")), 256)\n",
    ")\n",
    "\n",
    "(dim_reseau\n",
    " .select(\"reseau_sk\",\"code_reseau\",\"nom_reseau_amont\",\"code_reseau_amont\")\n",
    " .write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\")\n",
    " .option(\"path\", gold_dim_res).saveAsTable(\"hive_metastore.gold.dim_reseau\"))\n",
    "\n",
    "# -- DIM_PARAMETRE (depuis result_silver) --\n",
    "dim_parametre = (res\n",
    "    .select(\n",
    "        F.col(\"code_parametre\").alias(\"code_parametre\"),\n",
    "        F.col(\"code_parametre_sise_eau\").alias(\"code_parametre_sise_eau\"),\n",
    "        F.col(\"libelle_maj_parametre\").alias(\"libelle_maj_parametre\"),\n",
    "        F.col(\"libelle_min_parametre\").alias(\"libelle_min_parametre\"),\n",
    "        F.col(\"libelle_web_parametre\").alias(\"libelle_web_parametre\"),\n",
    "        F.col(\"code_unite_reference\").alias(\"code_unite_reference\"),\n",
    "        F.col(\"code_unite_reference_sise_eau\").alias(\"code_unite_reference_sise_eau\"),\n",
    "        F.col(\"limite_qualite\").alias(\"limite_qualite\"),\n",
    "        F.col(\"reference_qualite\").alias(\"reference_qualite\")\n",
    "    )\n",
    "    .where(F.col(\"code_parametre\").isNotNull())\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "dim_parametre = dim_parametre.withColumn(\n",
    "    \"parametre_sk\",\n",
    "    F.sha2(F.concat_ws(\"||\",\n",
    "        F.coalesce(F.col(\"code_parametre\"), F.lit(\"\")),\n",
    "        F.coalesce(F.col(\"code_unite_reference\"), F.lit(\"\")),\n",
    "        F.coalesce(F.col(\"libelle_maj_parametre\"), F.lit(\"\"))\n",
    "    ), 256)\n",
    ")\n",
    "\n",
    "(dim_parametre\n",
    " .select(\"parametre_sk\",\"code_parametre\",\"code_parametre_sise_eau\",\n",
    "         \"libelle_maj_parametre\",\"libelle_min_parametre\",\"libelle_web_parametre\",\n",
    "         \"code_unite_reference\",\"code_unite_reference_sise_eau\",\n",
    "         \"limite_qualite\",\"reference_qualite\")\n",
    " .write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\")\n",
    " .option(\"path\", gold_dim_par).saveAsTable(\"hive_metastore.gold.dim_parametre\"))\n",
    "\n",
    "# ========= FAITS =========\n",
    "\n",
    "# -- FACT_PRELEVEMENT (grain: 1 ligne / référence prélèvement) --\n",
    "# On associe commune & réseau via SK, et temps via date_key\n",
    "dim_temps_keyed = spark.table(\"hive_metastore.gold.dim_temps\").select(\n",
    "    F.col(\"date\").alias(\"d_date\"),\n",
    "    F.col(\"date_key\")\n",
    ")\n",
    "dim_commune_keyed = spark.table(\"hive_metastore.gold.dim_commune\").select(\n",
    "    \"commune_sk\",\"code_insee_commune\",\"code_dept\"\n",
    ")\n",
    "dim_reseau_keyed = spark.table(\"hive_metastore.gold.dim_reseau\").select(\n",
    "    \"reseau_sk\",\"code_reseau\"\n",
    ")\n",
    "\n",
    "f_prelev = (plv\n",
    "    .join(dim_commune_keyed, [\"code_insee_commune\",\"code_dept\"], \"left\")\n",
    "    .join(dim_reseau_keyed, [\"code_reseau\"], \"left\")\n",
    "    .join(dim_temps_keyed, plv[\"date_prelevement\"] == dim_temps_keyed[\"d_date\"], \"left\")\n",
    "    .select(\n",
    "        F.col(\"reference_prelevement\").alias(\"prelevement_ref\"),\n",
    "        F.col(\"annee\").alias(\"annee\"),\n",
    "        F.col(\"commune_sk\"),\n",
    "        F.col(\"reseau_sk\"),\n",
    "        F.col(\"date_key\"),\n",
    "        F.col(\"date_prelevement\"),\n",
    "        F.col(\"heure_prelevement\"),\n",
    "        F.col(\"pourcentage_debit\"),\n",
    "        F.col(\"conclusion_prelevement\"),\n",
    "        F.col(\"conformite_bacteriologiq\"),\n",
    "        F.col(\"conformite_chimique\"),\n",
    "        F.col(\"conformite_reference_bacteriologiq\"),\n",
    "        F.col(\"conformite_reference_chimique\"),\n",
    "        F.col(\"uge_libelle\"),\n",
    "        F.col(\"distri_libelle\"),\n",
    "        F.col(\"moa_libelle\"),\n",
    "        F.col(\"source\")\n",
    "    )\n",
    "    .dropDuplicates([\"prelevement_ref\"])  # au cas où\n",
    ")\n",
    "\n",
    "(f_prelev.write\n",
    " .format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\")\n",
    " .option(\"path\", gold_f_prelev).saveAsTable(\"hive_metastore.gold.fact_prelevement\"))\n",
    "\n",
    "# -- FACT_RESULTAT (grain: 1 ligne / résultat de paramètre / prélèvement) --\n",
    "# On relie res -> plv pour récupérer commune/réseau/date, puis dims paramètre & temps\n",
    "dim_param_keyed = spark.table(\"hive_metastore.gold.dim_parametre\").select(\n",
    "    \"parametre_sk\",\"code_parametre\",\"code_unite_reference\"\n",
    ")\n",
    "\n",
    "# Détection robuste d'une colonne \"valeur\" numérique parmi res_* (si noms variables)\n",
    "num_candidates = [c for c in res.columns if any(k in c.lower() for k in [\"valeur\", \"result\", \"mesure\"])]\n",
    "val_expr = None\n",
    "for c in num_candidates:\n",
    "    val_expr = F.coalesce(val_expr, F.col(c)) if val_expr is not None else F.col(c)\n",
    "# Valeur numérique (double) si trouvée, sinon null\n",
    "val_num = F.regexp_replace(val_expr, \",\", \".\").cast(\"double\") if val_expr is not None else F.lit(None).cast(\"double\")\n",
    "\n",
    "dp = dim_parametre.select(\n",
    "    F.col(\"parametre_sk\"),\n",
    "    F.col(\"code_parametre\").alias(\"dp_code_parametre\"),\n",
    "    F.col(\"code_unite_reference\").alias(\"dp_code_unite_reference\")\n",
    ")\n",
    "\n",
    "f_res = (res.alias(\"r\")\n",
    "    .join(plv.select(\n",
    "            \"reference_prelevement\",\"code_insee_commune\",\"code_dept\",\"code_reseau\",\"date_prelevement\",\"annee\"\n",
    "        ).alias(\"p\"),\n",
    "        F.col(\"r.reference_prelevement\")==F.col(\"p.reference_prelevement\"), \"left\")\n",
    "    .join(dim_commune_keyed.alias(\"c\"), [\"code_insee_commune\",\"code_dept\"], \"left\")\n",
    "    .join(dim_reseau_keyed.alias(\"re\"), [\"code_reseau\"], \"left\")\n",
    "    .join(dim_temps_keyed.alias(\"t\"), F.col(\"p.date_prelevement\")==F.col(\"t.d_date\"), \"left\")\n",
    "    .join(dp.alias(\"dp\"),\n",
    "          (F.col(\"r.code_parametre\") == F.col(\"dp.dp_code_parametre\")) &\n",
    "          ((F.col(\"r.code_unite_reference\") == F.col(\"dp.dp_code_unite_reference\")) |\n",
    "           F.col(\"dp.dp_code_unite_reference\").isNull()),\n",
    "          \"left\")\n",
    "    .select(\n",
    "        F.col(\"r.reference_prelevement\").alias(\"prelevement_ref\"),\n",
    "        F.col(\"r.annee\").alias(\"annee\"),\n",
    "        F.col(\"c.commune_sk\"),\n",
    "        F.col(\"re.reseau_sk\"),\n",
    "        F.col(\"t.date_key\"),\n",
    "        F.col(\"dp.parametre_sk\"),\n",
    "        val_num.alias(\"valeur_numerique\"),\n",
    "        F.col(\"r.qualite_parametre\"),\n",
    "        F.col(\"r.insitu_analyse\"),\n",
    "        F.col(\"r.rg_analyse\"),\n",
    "        F.col(\"r.code_unite_reference\"),\n",
    "        F.col(\"r.limite_qualite\"),\n",
    "        F.col(\"r.reference_qualite\"),\n",
    "        F.col(\"r.cas_parametre\"),\n",
    "        F.col(\"r.reference_analyse\").alias(\"reference_analyse\"),\n",
    "        F.col(\"r.source\")\n",
    "    )\n",
    ")\n",
    "\n",
    "(f_res.write\n",
    " .format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\")\n",
    " .option(\"path\", gold_f_res).saveAsTable(\"hive_metastore.gold.fact_resultat\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
