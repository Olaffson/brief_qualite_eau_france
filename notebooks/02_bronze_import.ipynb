{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7feea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import functions as F\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- Connexion stockage (clé dans les variables d'env du cluster) ---\n",
    "storage_account_name = os.environ[\"STORAGE_ACCOUNT_NAME\"]\n",
    "storage_account_key  = os.environ[\"STORAGE_ACCOUNT_KEY\"]\n",
    "\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net\",\n",
    "    storage_account_key\n",
    ")\n",
    "\n",
    "# --- Chemins ABFSS ---\n",
    "raw_plv_dir     = f\"abfss://raw@{storage_account_name}.dfs.core.windows.net/parquet_plv/\"\n",
    "raw_res_dir     = f\"abfss://raw@{storage_account_name}.dfs.core.windows.net/parquet_result/\"\n",
    "bronze_plv_dir  = f\"abfss://bronze@{storage_account_name}.dfs.core.windows.net/plv_bronze/\"\n",
    "bronze_res_dir  = f\"abfss://bronze@{storage_account_name}.dfs.core.windows.net/result_bronze/\"\n",
    "\n",
    "# --- Métastore / schéma ---\n",
    "spark.sql(\"USE CATALOG hive_metastore\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS bronze\")\n",
    "spark.sql(\"USE SCHEMA bronze\")\n",
    "\n",
    "years = [2021, 2022, 2023, 2024, 2025]\n",
    "\n",
    "# ======================= PLV =======================\n",
    "plv_paths = [f\"{raw_plv_dir}dis-plv-{y}.parquet\" for y in years]\n",
    "plv_dfs   = [spark.read.parquet(p) for p in plv_paths]\n",
    "plv_df    = reduce(lambda a, b: a.unionByName(b, allowMissingColumns=True), plv_dfs)\n",
    "\n",
    "(plv_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .option(\"path\", bronze_plv_dir)                                     # chemin Delta\n",
    "    .saveAsTable(\"hive_metastore.bronze.plv_bronze\"))                   # table métastore\n",
    "\n",
    "# ===================== RESULT ======================\n",
    "res_paths = [f\"{raw_res_dir}dis_result_{y}.parquet\" for y in years]\n",
    "res_dfs   = [spark.read.parquet(p) for p in res_paths]\n",
    "res_df    = reduce(lambda a, b: a.unionByName(b, allowMissingColumns=True), res_dfs)\n",
    "\n",
    "(res_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .option(\"path\", bronze_res_dir)\n",
    "    .saveAsTable(\"hive_metastore.bronze.result_bronze\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
